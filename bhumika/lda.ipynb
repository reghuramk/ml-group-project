{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #Helps find the best combination of model parameters\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, roc_auc_score, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize #Converts labels into a format suitable for multiclass metrics like ROC-AUC\n",
    "\n",
    "# loading dataset\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "y_bin = label_binarize(y, classes=np.unique(y))#Converts the labels into a binary format (One-vs-Rest approach), which is necessary for the ROC-AUC score calculation\n",
    "\n",
    "# splitting data\n",
    "X_train, X_test, y_train, y_test, y_bin_train, y_bin_test = train_test_split(X, y, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# hyperparameter tuning\n",
    "param_grid = [{\"solver\": [\"svd\"]}, {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [\"auto\"]}]\n",
    "grid_search = GridSearchCV(LinearDiscriminantAnalysis(), param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train) #trains the model with the best parameters found by GridSearchCV\n",
    "#solver: algorithm used to solve the LDA. testing different options (svd, lsqr, eigen), shrinkage: this is used to apply regularization to some solvers like lsqr and eigen, GridSearchCV: tests different combinations of parameters and finds the best one using 5-fold cross-validation\n",
    "\n",
    "\n",
    "lda = grid_search.best_estimator_\n",
    "y_pred = lda.predict(X_test)\n",
    "y_prob = lda.predict_proba(X_test)\n",
    "\n",
    "# evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_bin_test, y_prob, multi_class='ovr'):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=\"Blues\"), plt.colorbar()\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.title(\"Confusion Matrix\"), plt.xlabel(\"Predicted\"), plt.ylabel(\"True\"), plt.show()\n",
    "\n",
    "# ROC curve\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(y_bin.shape[1]):\n",
    "    fpr, tpr, _ = roc_curve(y_bin_test[:, i], y_prob[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"Digit {i} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\"), plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multiclass ROC Curve\"), plt.legend(), plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
